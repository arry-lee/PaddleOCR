# This .py is auto generated by the script in the root folder.
from ptocr.config import ConfigModel, _
from ptocr.modules.backbones.vqa_layoutlm import LayoutLMv2ForRe
from ptocr.loss.basic import LossFromOutput
from ptocr.metrics.vqa import VQAReTokenMetric
from torch.optim import AdamW
from torch.optim.lr_scheduler import ConstantLR
from ptocr.postprocess.vqa import VQAReTokenLayoutLMPostProcess
from ptocr.datasets.simple import SimpleDataSet
from ptocr.transforms.operators import (
    ToCHWImage,
    DecodeImage,
    NormalizeImage,
    KeepKeys,
    Resize,
)
from ptocr.transforms.label_ops import VQATokenLabelEncode
from ptocr.transforms.vqa.token.vqa_token_pad import VQATokenPad
from ptocr.transforms.vqa.token.vqa_token_relation import VQAReTokenRelation
from ptocr.transforms.vqa.token.vqa_token_chunk import VQAReTokenChunk


class Model(ConfigModel):
    use_gpu = True
    epoch_num = 200
    log_window_size = 10
    log_batch_step = 10
    save_model_dir = "./output/re_layoutlmv2_xfund_zh"
    save_epoch_step = 2000
    eval_batch_step = [0, 19]
    metric_during_train = False
    save_infer_dir = None
    use_visualdl = False
    seed = 2022
    infer_img = "ppstructure/docs/kie/input/zh_val_21.jpg"
    save_res_path = "./output/re_layoutlmv2_xfund_zh/res/"
    model_type = "kie"
    algorithm = "LayoutLMv2"
    Transform = None
    Backbone = _(LayoutLMv2ForRe, pretrained=True, checkpoints=None)
    loss = LossFromOutput(key="loss", reduction="mean")
    metric = VQAReTokenMetric(main_indicator="hmean")
    Optimizer = _(AdamW, beta1=0.9, beta2=0.999, clip_norm=10, lr=5e-05)
    LRScheduler = _(ConstantLR, warmup_epoch=10)
    PostProcessor = _(
        VQAReTokenLayoutLMPostProcess,
    )

    class Train:
        Dataset = _(
            SimpleDataSet,
            data_dir="train_data/XFUND/zh_train/image",
            label_file_list=["train_data/XFUND/zh_train/train.json"],
            ratio_list=[1.0],
        )
        transforms = _[
            DecodeImage(img_mode="RGB", channel_first=False),
            VQATokenLabelEncode(
                contains_re=True,
                algorithm="LayoutLMv2",
                class_path="train_data/XFUND/class_list_xfun.txt",
            ),
            VQATokenPad(max_seq_len=512, return_attention_mask=True),
            VQAReTokenRelation(),
            VQAReTokenChunk(max_seq_len=512),
            Resize(size=[224, 224]),
            NormalizeImage(
                scale="1./255.",
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
                order="hwc",
            ),
            ToCHWImage(),
            KeepKeys(
                keep_keys=[
                    "input_ids",
                    "bbox",
                    "attention_mask",
                    "token_type_ids",
                    "image",
                    "entities",
                    "relations",
                ]
            ),
        ]
        DATALOADER = _(
            shuffle=True,
            drop_last=False,
            batch_size=8,
            num_workers=8,
            collate_fn="ListCollator",
        )

    class Eval:
        Dataset = _(
            SimpleDataSet,
            data_dir="train_data/XFUND/zh_val/image",
            label_file_list=["train_data/XFUND/zh_val/val.json"],
        )
        transforms = _[
            DecodeImage(img_mode="RGB", channel_first=False),
            VQATokenLabelEncode(
                contains_re=True,
                algorithm="LayoutLMv2",
                class_path="train_data/XFUND/class_list_xfun.txt",
            ),
            VQATokenPad(max_seq_len=512, return_attention_mask=True),
            VQAReTokenRelation(),
            VQAReTokenChunk(max_seq_len=512),
            Resize(size=[224, 224]),
            NormalizeImage(
                scale="1./255.",
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
                order="hwc",
            ),
            ToCHWImage(),
            KeepKeys(
                keep_keys=[
                    "input_ids",
                    "bbox",
                    "attention_mask",
                    "token_type_ids",
                    "image",
                    "entities",
                    "relations",
                ]
            ),
        ]
        DATALOADER = _(
            shuffle=False,
            drop_last=False,
            batch_size=8,
            num_workers=8,
            collate_fn="ListCollator",
        )

# This .py is auto generated by the script in the root folder.
import os
import sys
from collections import defaultdict

import numpy as np

sys.path.append(os.getcwd())

from ptocr.config import ConfigModel, _
from ptocr.modules.backbones.rec_mv1_enhance import MobileNetV1Enhance
from ptocr.modules.necks.rnn import SequenceEncoder
from ptocr.modules.heads.ctc import CTCHead
from ptocr.loss.compose import CombinedLoss
from ptocr.metrics.rec import RecMetric
from ptocr.postprocess.rec import CTCLabelDecode
from torch.optim import Adam
from ptocr.optim.lr_scheduler import PiecewiseLR
from ptocr.datasets.simple import SimpleDataSet
from ptocr.transforms.operators import KeepKeys, DecodeImage
from ptocr.transforms.rec_img_aug import RecAug, RecResizeImg
from ptocr.transforms.label_ops import CTCLabelEncode


class Model(ConfigModel):
    debug = False
    use_gpu = True
    epoch_num = 800
    log_window_size = 20
    log_batch_step = 10
    save_model_dir = "./output/rec_mobile_pp-OCRv2_enhanced_ctc_loss"
    save_epoch_step = 3
    eval_batch_step = [0, 2000]
    metric_during_train = True
    pretrained_model = None
    checkpoints = None
    save_infer_dir = None
    use_visualdl = False
    infer_img = "doc/imgs_words/ch/word_1.jpg"
    character_dict_path = "ptocr/utils/ppocr_keys_v1.txt"
    max_text_length = 25
    infer_mode = False
    use_space_char = True
    distributed = False
    save_res_path = (
        "./output/rec/predicts_mobile_pp-OCRv2_enhanced_ctc_loss.txt"
    )
    model_type = "rec"
    algorithm = "CRNN"

    postprocessor = CTCLabelDecode(character_dict_path,use_space_char)

    Transform = None
    Backbone = _(MobileNetV1Enhance, scale=0.5)
    Neck = _(SequenceEncoder, encoder_type="rnn", hidden_size=64)
    Head = _(CTCHead, out_channels=len(postprocessor.character), mid_channels=96, fc_decay=2e-05, return_feats=True)
    loss = CombinedLoss(
        loss_config_list=[
            {"CTCLoss": {"use_focal_loss": False, "weight": 1.0}},
            {
                "CenterLoss": {
                    "weight": 0.05,
                    "num_classes": 6625,
                    "feat_dim": 96,
                    "center_file_path": None,
                }
            },
        ]
    )
    metric = RecMetric(main_indicator="acc")
    Optimizer = _(Adam, betas=[0.9, 0.999])
    LRScheduler = _(
        PiecewiseLR, decay_epochs=[700], values=[0.001, 0.0001], warmup_epoch=5
    )

    class Train:
        Dataset = _(
            SimpleDataSet,
            root="./train_data/",
            label_files=["./train_data/train_list.txt"],
        )
        transforms = _[
            DecodeImage(img_mode="BGR", channel_first=False),
            RecAug(),
            CTCLabelEncode(max_text_length=25,character_dict_path="ptocr/utils/ppocr_keys_v1.txt",use_space_char=True),
            RecResizeImg(image_shape=[3, 32, 320]),
            KeepKeys(keep_keys=["image", "label", "length", "label_ace"]),
        ]
        DATALOADER = _(
            shuffle=True, batch_size=128, drop_last=True, num_workers=8
        )

    class Eval:
        Dataset = _(
            SimpleDataSet,
            root="./train_data",
            label_files=["./train_data/val_list.txt"],
        )
        transforms = _[
            DecodeImage(img_mode="BGR", channel_first=False),
            CTCLabelEncode(max_text_length=25,character_dict_path="ptocr/utils/ppocr_keys_v1.txt",use_space_char=True),
            RecResizeImg(image_shape=[3, 32, 320]),
            KeepKeys(keep_keys=["image", "label", "length"]),
        ]
        DATALOADER = _(
            shuffle=False, drop_last=False, batch_size=128, num_workers=8
        )

    class Infer:
        transforms = _[
            DecodeImage(img_mode="BGR", channel_first=False),
            # CTCLabelEncode(character_dict_path="ptocr/utils/ppocr_keys_v1.txt",use_space_char=True),
            RecResizeImg(image_shape=[3, 32, 320],infer_mode=True),
            KeepKeys(keep_keys=["image", "label", "length"]),
        ]
def transmodel():
    import torch
    import paddle


    def p2t(tensor) -> torch.Tensor:
        if isinstance(tensor, paddle.Tensor):
            return torch.from_numpy(tensor.numpy())
        if isinstance(tensor,np.ndarray):
            return torch.from_numpy(tensor)
    def cv(dp, dt):
        pp = {'neck.encoder.lstm.0.cell_bw.bias_ih', 'neck.encoder.lstm.1.cell_bw.weight_hh',
              'neck.encoder.lstm.0.cell_bw.weight_hh', 'neck.encoder.lstm.1.cell_fw.bias_ih',
              'neck.encoder.lstm.1.cell_bw.weight_ih', 'neck.encoder.lstm.0.cell_fw.weight_hh',
              'neck.encoder.lstm.1.cell_fw.weight_ih', 'neck.encoder.lstm.0.cell_fw.weight_ih',
              'neck.encoder.lstm.1.cell_fw.weight_hh', 'neck.encoder.lstm.0.cell_fw.bias_ih',
              'neck.encoder.lstm.0.cell_fw.bias_hh', 'neck.encoder.lstm.1.cell_fw.bias_hh',
              'neck.encoder.lstm.0.cell_bw.weight_ih', 'neck.encoder.lstm.0.cell_bw.bias_hh',
              'neck.encoder.lstm.1.cell_bw.bias_hh', 'neck.encoder.lstm.1.cell_bw.bias_ih'}

        pt = {'neck.encoder.lstm.bias_ih_l1', 'neck.encoder.lstm.weight_ih_l0_reverse',
              'neck.encoder.lstm.weight_hh_l0', 'neck.encoder.lstm.weight_hh_l1',
              'neck.encoder.lstm.weight_ih_l1_reverse', 'neck.encoder.lstm.weight_hh_l1_reverse',
              'neck.encoder.lstm.bias_hh_l0', 'neck.encoder.lstm.bias_ih_l1_reverse',
              'neck.encoder.lstm.bias_hh_l0_reverse', 'neck.encoder.lstm.bias_ih_l0',
              'neck.encoder.lstm.bias_ih_l0_reverse', 'neck.encoder.lstm.bias_hh_l1', 'neck.encoder.lstm.weight_ih_l0',
              'neck.encoder.lstm.weight_hh_l0_reverse', 'neck.encoder.lstm.weight_ih_l1',
              'neck.encoder.lstm.bias_hh_l1_reverse'}

        d = defaultdict(list)
        for i in pp:
            s = i.removeprefix("neck.encoder.lstm.")
            k = s[0] == '0'
            bf = 'bw' in s
            bw = 'bias' in s
            ih = 'ih' in s
            key = str((k, bf, bw, ih))
            d[key].append(i)

        for i in pt:
            s = i.removeprefix("neck.encoder.lstm.")
            k = 'l0' in s
            bf = 'reverse' in s
            bw = 'bias' in s
            ih = 'ih' in s
            key = str((k, bf, bw, ih))
            d[key].append(i)
        for k in d:
            dt[d[k][1]] = p2t(dp[d[k][0]])

    m = Model()
    x = m.model.state_dict()  # save("/output/rec_svtr/zero.pth")

    t_keys = [k for k in x.keys() if not k.endswith(".num_batches_tracked")]
    # print(t_keys)
    paddle_params = paddle.load(
        r'C:\Users\dell\.toddleocr\whl\rec\ch\ch_PP-OCRv2_rec_infer\inference'
    )
    print(type(paddle_params))

    keys = list(paddle_params.keys())
    keys.sort()
    # print(keys)
    print(len(t_keys), len(keys))
    maps = {
        "bn.running_mean": "_batch_norm._mean",
        "bn.running_var": "_batch_norm._variance",
        "bn.bias": "_batch_norm.bias",
        "bn.weight": "_batch_norm.weight",
        "conv.weight": "_conv.weight",
    }
    tset = set()
    for k in t_keys:
        l, m, r = k.rsplit(".", 2)
        if m + "." + r in maps:
            k = l + "." + maps[m + "." + r]
        tset.add(k)

    pset = set(keys)
    u = pset - tset
    print(u)
    print(len(u))

    u = tset-pset
    print(u)
    print(len(u))

    d = {}
    cv(paddle_params, d)
    for k, v in x.items():
        l, m, r = k.rsplit(".", 2)
        if m + "." + r in maps:
            kk = l + "." + maps[m + "." + r]
        else:
            kk = k

        if kk.endswith('num_batches_tracked'):
            d[k] = torch.tensor(200)
        elif kk.startswith("neck.encoder.lstm"):
            continue
        else:
            d[k] = p2t(paddle_params[kk])

        if "fc" in k:
            d[k] = d[k].T

    torch.save(d, "model/ch_PP-OCRv2_rec_infer/inference.pth")

    for k, v in paddle_params.items():
        if k in u:
            print(k, v.shape)
        elif k.startswith("neck.encoder.lstm"):
            print(k, v.shape)
        if k == "neck.encoder.lstm.weight_ih_l0":
            print(k, v)
        if k == "neck.encoder.lstm.0.cell_fw.weight_ih":
            print(k, v)


if __name__ == "__main__":
    transmodel()

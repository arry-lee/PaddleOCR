Global:
  use_gpu: true
  epoch_num: 500
  log_smooth_window: 20
  print_batch_step: 10
  save_model_dir: ./output/sr/sr_tsrn_transformer_strock/
  save_epoch_step: 3
  # evaluation is run every 2000 iterations
  eval_batch_step: [ 0, 1000 ]
  cal_metric_during_train: False
  pretrained_model:
  checkpoints:
  save_inference_dir: sr_output
  use_visualdl: False
  infer_img: doc/imgs_words_en/word_52.png
  # for data or label process
  character_dict_path: ./train_data/srdata/english_decomposition.txt
  max_text_length: 100
  infer_mode: False
  use_space_char: False
  save_res_path: ./output/sr/predicts_gestalt.txt

Optimizer:
  class: Adam
  beta1: 0.5
  beta2: 0.999
  clip_norm: 0.25
LRScheduler:
  class: ConstantLR

Model:
  model_type: sr
  algorithm: Gestalt
  Transform:
    class: TSRN
    STN: True
    infer_mode: False

Loss:
  class: StrokeFocusLoss
  character_dict_path: ./train_data/srdata/english_decomposition.txt

PostProcessor:
  class: None

Metric:
  class: SRMetric
  main_indicator: all

Train:
  Dataset:
    class: LMDBDataSetSR
    data_dir: ./train_data/srdata/train
    transforms:
      - class: SRResize
        imgH: 32
        imgW: 128
        down_sample_scale: 2
      - class: SRLabelEncode # Class handling label
      - class: KeepKeys
        keep_keys: [ 'img_lr', 'img_hr', 'length', 'input_tensor', 'label' ] # dataloader will return list in this order
  DataLoader:
    shuffle: False
    batch_size: 16
    drop_last: True
    num_workers: 4

Eval:
  Dataset:
    class: LMDBDataSetSR
    data_dir: ./train_data/srdata/test
    transforms:
      - class: SRResize
        imgH: 32
        imgW: 128
        down_sample_scale: 2
      - class: SRLabelEncode # Class handling label
      - class: KeepKeys
        keep_keys: [ 'img_lr', 'img_hr','length', 'input_tensor', 'label' ] # dataloader will return list in this order
  DataLoader:
    shuffle: False
    drop_last: False
    batch_size: 16
    num_workers: 4

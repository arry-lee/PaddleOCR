Global:
  use_gpu: True
  epoch_num: &epoch_num 200
  log_smooth_window: 10
  print_batch_step: 10
  save_model_dir: ./output/ser_layoutlm_xfund_zh
  save_epoch_step: 2000
  # evaluation is run every 10 iterations after the 0th iteration
  eval_batch_step: [ 0, 19 ]
  cal_metric_during_train: False
  save_inference_dir:
  use_visualdl: False
  seed: 2022
  infer_img: ppstructure/docs/kie/input/zh_val_42.jpg
  save_res_path: ./output/re_layoutlm_xfund_zh/res

Model:
  model_type: kie
  algorithm: &algorithm "LayoutLM"
  Transform:
  Backbone:
    class: LayoutLMForSer
    pretrained: True
    checkpoints:
    num_classes: &num_classes 7

Loss:
  class: VQASerTokenLayoutLMLoss
  num_classes: *num_classes

Optimizer:
  class: AdamW
  beta1: 0.9
  beta2: 0.999
  lr: 0.00005
LRScheduler:
  class: Linear
  
  epochs: *epoch_num
  warmup_epoch: 2


PostProcessor:
  class: VQASerTokenLayoutLMPostProcess
  class_path: &class_path train_data/XFUND/class_list_xfun.txt

Metric:
  class: VQASerTokenMetric
  main_indicator: hmean

Train:
  Dataset:
    class: SimpleDataSet
    data_dir: train_data/XFUND/zh_train/image
    label_file_list:
      - train_data/XFUND/zh_train/train.json
    ratio_list: [ 1.0 ]
    transforms:
      - class: DecodeImage # load image
        img_mode: RGB
        channel_first: False
      - class: VQATokenLabelEncode # Class handling label
        contains_re: False
        algorithm: *algorithm
        class_path: *class_path
      - class: VQATokenPad
        max_seq_len: &max_seq_len 512
        return_attention_mask: True
      - class: VQASerTokenChunk
        max_seq_len: *max_seq_len
      - class: Resize
        size: [ 224,224 ]
      - class: NormalizeImage
        scale: 1
        mean: [ 123.675, 116.28, 103.53 ]
        std: [ 58.395, 57.12, 57.375 ]
        order: 'hwc'
      - class: ToCHWImage
      - class: KeepKeys
        keep_keys: [ 'input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'image', 'labels' ] # dataloader will return list in this order
  DataLoader:
    shuffle: True
    drop_last: False
    batch_size: 8
    num_workers: 4

Eval:
  Dataset:
    class: SimpleDataSet
    data_dir: train_data/XFUND/zh_val/image
    label_file_list:
      - train_data/XFUND/zh_val/val.json
    transforms:
      - class: DecodeImage # load image
        img_mode: RGB
        channel_first: False
      - class: VQATokenLabelEncode # Class handling label
        contains_re: False
        algorithm: *algorithm
        class_path: *class_path
      - class: VQATokenPad
        max_seq_len: *max_seq_len
        return_attention_mask: True
      - class: VQASerTokenChunk
        max_seq_len: *max_seq_len
      - class: Resize
        size: [ 224,224 ]
      - class: NormalizeImage
        scale: 1
        mean: [ 123.675, 116.28, 103.53 ]
        std: [ 58.395, 57.12, 57.375 ]
        order: 'hwc'
      - class: ToCHWImage
      - class: KeepKeys
        keep_keys: [ 'input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'image', 'labels' ] # dataloader will return list in this order
  DataLoader:
    shuffle: False
    drop_last: False
    batch_size: 8
    num_workers: 4

# This .py is auto generated by the script in the root folder.
from configs.config import ConfigModel,_
from ppocr.modeling.backbones.rec_densenet import DenseNet
from ppocr.modeling.heads.rec_can_head import CANHead
from ppocr.losses.rec_can_loss import CANLoss
from ppocr.metrics.rec_metric import CANMetric
from torch.nn import Momentum, TwoStepCosine
from ppocr.postprocess.rec_postprocess import CANLabelDecode
from ppocr.data.simple_dataset import SimpleDataSet
from ppocr.data.imaug.operators import KeepKeys, DecodeImage, NormalizeImage, GrayImageChannelFormat
from ppocr.data.imaug.label_ops import CANLabelEncode
class Model(ConfigModel):
    use_gpu = True
    epoch_num = 240
    log_window_size = 20
    log_batch_step = 10
    save_model_dir = "./output/rec/can/"
    save_epoch_step = 1
    eval_batch_step = [0, 1105]
    metric_during_train = True
    pretrained_model = None
    checkpoints = None
    save_infer_dir = None
    use_visualdl = False
    infer_img = "doc/datasets/crohme_demo/hme_00.jpg"
    character_dict_path = "ppocr/utils/dict/latex_symbol_dict.txt"
    max_text_length = 36
    infer_mode = False
    use_space_char = False
    save_res_path = "./output/rec/predicts_can.txt"
    model_type = 'rec'
    algorithm = 'CAN'
    in_channels = 1
    Transform = None
    Backbone = _(DenseNet, grow_rate=24, reduction=0.5, bottleneck=True, use_dropout=True, input_channel=1)
    Head = _(CANHead, in_channel=684, out_channel=111, max_text_length=36, ratio=16, attdecoder={'is_train': True, 'input_size': 256, 'hidden_size': 256, 'encoder_out_channel': 684, 'dropout': True, 'dropout_ratio': 0.5, 'word_num': 111, 'counting_decoder_out_channel': 111, 'attention': {'attention_dim': 512, 'word_conv_kernel': 1}})
    loss = CANLoss()
    metric = CANMetric(main_indicator="exp_rate")
    Optimizer = _(Momentum,momentum=0.9, clip_norm_global=100.0, lr=0.01)
    LRScheduler = _(TwoStepCosine,warmup_epoch=1, weight_decay=0.0001)
    PostProcessor = _(CANLabelDecode,)
    class Train:
        Dataset = _(SimpleDataSet, data_dir="./train_data/CROHME/training/images/", label_file_list=['./train_data/CROHME/training/labels.txt'])
        transforms = _[DecodeImage(channel_first=False), NormalizeImage(mean=[0, 0, 0], std=[1, 1, 1], order="hwc"), GrayImageChannelFormat(inverse=True), CANLabelEncode(lower=False), KeepKeys(keep_keys=['image', 'label'])]
        DATALOADER = _(shuffle=True, batch_size=8, drop_last=False, num_workers=4, collate_fn="DyMaskCollator")
    class Eval:
        Dataset = _(SimpleDataSet, data_dir="./train_data/CROHME/evaluation/images/", label_file_list=['./train_data/CROHME/evaluation/labels.txt'])
        transforms = _[DecodeImage(channel_first=False), NormalizeImage(mean=[0, 0, 0], std=[1, 1, 1], order="hwc"), GrayImageChannelFormat(inverse=True), CANLabelEncode(lower=False), KeepKeys(keep_keys=['image', 'label'])]
        DATALOADER = _(shuffle=False, drop_last=False, batch_size=1, num_workers=4, collate_fn="DyMaskCollator")
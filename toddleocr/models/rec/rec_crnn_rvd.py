# This .py is auto generated by the script in the root folder.
import os
import sys

sys.path.append(os.getcwd())
from toddleocr.config import _, ConfigModel
from toddleocr.datasets.simple import SimpleDataSet
from toddleocr.loss.ctc import CTCLoss
from toddleocr.metrics.rec import RecMetric
from toddleocr.modules.backbones.resnet.rec_resnet_vd import ResNet_Rec_Vd
from toddleocr.modules.heads.ctc import CTCHead
from toddleocr.modules.necks.rnn import SequenceEncoder
from toddleocr.postprocess.rec import CTCLabelDecode
from toddleocr.transforms import CTCLabelEncode, DecodeImage, KeepKeys, RecAug, RecResizeImg
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts


class Model(ConfigModel):
    use_gpu = True
    epoch_num = 500
    log_window_size = 20
    log_batch_step = 10
    save_model_dir = "./output/rec_chinese_common_v2.0"
    save_epoch_step = 3
    eval_batch_step = [0, 2000]
    metric_during_train = True
    pretrained_model = None
    checkpoints = None
    save_infer_dir = None
    use_visualdl = False
    infer_img = "doc/imgs_words/ch/word_1.jpg"
    character_dict_path = "toddleocr/utils/ppocr_keys_v1.txt"
    max_text_length = 25
    infer_mode = False
    use_space_char = True
    save_res_path = "./output/rec/predicts_chinese_common_v2.0.txt"
    model_type = "rec"
    algorithm = "CRNN"
    loss = CTCLoss()
    metric = RecMetric(main_indicator="acc")
    postprocessor = CTCLabelDecode(
        character_dict_path=character_dict_path, use_space_char=True
    )

    Transform = None
    Backbone = _(ResNet_Rec_Vd, layers=34)
    Neck = _(SequenceEncoder, encoder_type="rnn", hidden_size=256)
    Head = _(CTCHead, out_channels=len(postprocessor.character), fc_decay=4e-05)

    Optimizer = _(Adam, betas=[0.9, 0.999], lr=0.001)
    LRScheduler = _(CosineAnnealingWarmRestarts, T_0=5)

    class Train:
        Dataset = _(
            SimpleDataSet,
            root="./train_data/",
            label_files=["./train_data/train_list.txt"],
        )
        transforms = _[
            DecodeImage(img_mode="BGR", channel_first=False),
            RecAug(),
            CTCLabelEncode(
                max_text_length=25,
                character_dict_path="toddleocr/utils/ppocr_keys_v1.txt",
                use_space_char=True,
            ),
            RecResizeImg(
                image_shape=[3, 32, 320],
                character_dict_path="toddleocr/utils/ppocr_keys_v1.txt",
            ),
            KeepKeys(keep_keys=["image", "label", "length"]),
        ]
        DATALOADER = _(shuffle=True, batch_size=256, drop_last=True, num_workers=8)

    class Eval:
        Dataset = _(
            SimpleDataSet,
            root="./train_data/",
            label_files=["./train_data/val_list.txt"],
        )
        transforms = _[
            DecodeImage(img_mode="BGR", channel_first=False),
            CTCLabelEncode(
                max_text_length=25,
                character_dict_path="toddleocr/utils/ppocr_keys_v1.txt",
                use_space_char=True,
            ),
            RecResizeImg(
                image_shape=[3, 32, 320],
                character_dict_path="toddleocr/utils/ppocr_keys_v1.txt",
            ),
            KeepKeys(keep_keys=["image", "label", "length"]),
        ]
        DATALOADER = _(shuffle=False, drop_last=False, batch_size=256, num_workers=8)

    class Infer:
        transforms = _[
            DecodeImage(img_mode="BGR", channel_first=False),
            RecResizeImg(
                image_shape=[3, 32, 320],
                infer_mode=True,
                character_dict_path="toddleocr/utils/ppocr_keys_v1.txt",
            ),
            KeepKeys(keep_keys=["image"]),
        ]


def transmodel():
    import paddle
    import torch

    def p2t(tensor) -> torch.Tensor:
        return torch.from_numpy(tensor.numpy())

    m = Model()
    x = m.model.state_dict()  # save("/output/rec_svtr/zero.pth")

    t_keys = [k for k in x.keys() if not k.endswith(".num_batches_tracked")]
    # print(t_keys)
    paddle_params = paddle.load(
        r"D:\dev\github\ToddleOCR\model\ch_ppocr_server_v2.0_rec_train\best_accuracy.pdparams"
    )
    print(type(paddle_params))

    keys = list(paddle_params.keys())
    keys.sort()
    # print(keys)
    print(len(t_keys), len(keys))
    maps = {
        "bn.running_mean": "_batch_norm._mean",
        "bn.running_var": "_batch_norm._variance",
        "bn.bias": "_batch_norm.bias",
        "bn.weight": "_batch_norm.weight",
        "conv.weight": "_conv.weight",
    }
    tset = set()
    for k in t_keys:
        l, m, r = k.rsplit(".", 2)
        if m + "." + r in maps:
            k = l + "." + maps[m + "." + r]
        tset.add(k)

    pset = set(keys)
    u = pset - tset
    print(u)
    print(len(u))
    d = {}
    for k, v in x.items():
        l, m, r = k.rsplit(".", 2)
        if m + "." + r in maps:
            kk = l + "." + maps[m + "." + r]
        else:
            kk = k
        d[k] = p2t(paddle_params[kk])

        if "fc" in k:
            d[k] = d[k].T

    torch.save(d, "model/ch_ppocr_server_v2.0_rec_train/best_accuracy.pth")

    for k, v in paddle_params.items():
        if k in u:
            print(k, v.shape)
        elif k.startswith("neck.encoder.lstm"):
            print(k, v.shape)
        if k == "neck.encoder.lstm.weight_ih_l0":
            print(k, v)
        if k == "neck.encoder.lstm.0.cell_fw.weight_ih":
            print(k, v)


if __name__ == "__main__":
    transmodel()
